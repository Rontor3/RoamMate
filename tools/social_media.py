from fastmcp import FastMCP
import asyncpraw

# Import your mcp instance from main.py or create here if standalone example
# from main import mcp

# For demo, create MCP server instance here
mcp = FastMCP("SocialTools")

# Reddit API credentials (replace with your real credentials or load from env)
CLIENT_ID = "oFMO4ZLCcBlIBA-mm8S0Lg"
CLIENT_SECRET = "YbtVC-TdjvvFIPdbQo5mqogYdWdULTw"
USER_AGENT = "our_platform:roam_mate:v1.0 (by u/Admirable-Star-1447)"


@mcp.tool
async def get_reddit_insights( queries: list) -> list[str]:
    """
    Perform multiple filtered Reddit searches in a subreddit.

    Args:
        subreddit_name: Name of the subreddit to search.
        queries: List of search queries generated by LLM.
        comment_keyword: Keyword to filter relevant comments.

    Returns:
        Dictionary with 'all_time_best' and 'recent_trends' keys, each containing lists of posts with relevant comments.
    """

    results = {
        "all_time_best": [],
        "recent_trends": []
    }

    async with asyncpraw.Reddit(
        client_id=CLIENT_ID,
        client_secret=CLIENT_SECRET,
        user_agent=USER_AGENT
    ) as reddit:

        subreddit = await reddit.subreddit('all')

        # Helper function to fetch posts for query with given filters
        async def fetch_posts(query, sort, time_filter, limit):
            posts_list = []
            async for post in subreddit.search(query, sort=sort, time_filter=time_filter, limit=limit):
                await post.comments.replace_more(limit=0)  # Fetch all comments
                relevant_comments = [c.body for c in post.comments.list() if c.body]



                posts_list.append({
                    "title": post.title,
                    "score": post.score,
                    "url": post.url,
                    "id": post.id,
                    "created_utc": post.created_utc,
                    "permalink": f"https://reddit.com{post.permalink}",
                    "relevant_comments": relevant_comments,
                })
            all_texts = []
            for post in posts_list:
                full_text = f"TITLE: {post.title}\nTEXT: {post.selftext}\nCOMMENTS: {' '.join(post.relevant_comments)}\nDateofcreation: {post.created_utc}"
                all_texts.append(full_text)    

            return all_texts
        
        for query in queries:
            top_posts = await fetch_posts(query, sort="top", time_filter="year", limit=10)
            results["all_time_best"].extend(top_posts)
            recent_posts = await fetch_posts(query, sort="top", time_filter="month", limit=10)
            results["recent_trends"].extend(recent_posts)



    return results    
def generate_reddit_search_queries(user_prefs):
    enerate_reddit_search_queries(user_prefs):
    return [f"travel {user_prefs['location']}"]





@mcp.tool
async def scrape_and_extract_travel_advice(subreddit, user_prefs, post_limit) -> dict:
    queries = generate_reddit_search_queries(user_prefs)   ##used for extracting the queries from the user preferences
    all_posts_text = get_reddit_insights(queries)         ##used for getting the posts from the queries
    prompt = build_llm_prompt(user_prefs, all_posts_text) ##used for building the prompt for the LLM
    extraction = await extract_travel_insights_with_llm(prompt) ##used for extracting the insights from the LLM
    return extraction
        

